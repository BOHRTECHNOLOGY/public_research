#!/usr/bin/env python
import pandas as pd
import networkx as nx
import numpy as np
import time
import argparse
from argparse import RawTextHelpFormatter
import os
from vehicles import generate_vehicles
import sys
import logging as log

# Nasty trick to get `ortools_engine` from parent directory
# TODO change it when correct python package structure will be created
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import ortools_engine

DESCRIPTION = '''
Vehicle Routing Problem solver.
Solver requires following `*.csv` data files:
    a) `outposts.csv`
    b) `graph.csv`
    c) `vehicles.csv`

Use `outposts.py` and `graph.py` scripts to generate required datafiles.

If list of vehicles are unknown, you can use `--gen_vehicles` flag.
Use `vehicles.py` to generate list of vehicles into supproted csv file.
'''

INFO = '=' * 80 + '''
Data directory: {datadir:}
Solver: {solver:}
Time elapsed [min]: {elapsed:}
Results saved in: {savepath:}
'''

# List of available solvers
# First will be the default one
SOLVERS = [
    ('ortools', ortools_engine)
]


def outposts_preprocessing(outposts, vehicles):
    '''
    Preprocess outposts list looking on `load` value.
    Delegate single vehicles to single outposts when corresponing `load`
    is greater than available max. single vehicle capacity.

    Args:
        outposts: DataFrame of outposts
        vehicles: DataFrame of vehicles

    Returns:
        Tuple of:
        * updated outposts
        * DataFrame of available vehicles
        * list of (outpost id, vehicle used, vehicle capacity)

        If all vehicles will be used during this phase returns `(None, None, None)`.
    '''
    vehicles_sorted = vehicles.sort_values(by=['capacity'], ascending=False)
    vehicles_idx = 0
    vehicles_number = len(vehicles_sorted)
    vehicles_used = []
    for idx, row in outposts.iterrows():
        while True:
            vehicle = vehicles_sorted.iloc[vehicles_idx]
            capacity = vehicle.capacity
            if row['load'] < capacity:
                break
            row['load'] = row['load'] - capacity
            outposts.loc[idx] = row
            vehicles_used += [(idx, int(vehicle.vehicle_id), capacity)]
            vehicles_idx += 1
            if vehicles_idx >= vehicles_number:
                return None, None, None

    vehicles_left = vehicles_sorted.iloc[list(range(vehicles_idx, vehicles_number))]
    vehicles_left = vehicles_left.sort_values(by=['vehicle_id']).reset_index()
    vehicles_left = vehicles_left[['vehicle_id', 'capacity']]
    return outposts, vehicles_left, vehicles_used


def append_single_outposts_routes(routes, starting_point, vehicles_used, graph):
    '''
    Append single outpost solutions from preprocessing phase to set of
    solutions generated by solver engine.

    Agrs:
        routes: solutions found by solver
        starting_point: starting outpost id
        vehicles_used: list of (outpost id, vehicle id, capacity)
        graph: `nx.Graph` instance describing connections between outposts

    Returns:
        DataFrame containing all routes.
    '''
    cols = ['vehicle_id', 'route', 'cost']
    for outpost_id, vehicle_id, _ in vehicles_used:
        vals = [
            vehicle_id, 
            [starting_point, outpost_id, starting_point],
            2 * graph.edges[(starting_point, outpost_id)]['weight']
        ]
        routes = routes.append(dict(zip(cols, vals)), ignore_index=True)
    return routes


def read_graph_from_df(graph_df, outposts):
    '''
    Creates graph consisted of nodes (outposts) with an associated `load`
    and weighted edges which describe cost of commutation between points.

    Args:
        graph_df: DataFrame describing connections between outposts
        outposts: DataFrame describing outposts
    
    Returns:
        `nx.Graph` instance
    '''
    graph = nx.Graph()
    for idx, outpost in outposts.iterrows():
        graph.add_node(idx, load=outpost.load)
    for _, row in graph_df.iterrows():
        graph.add_edge(row["node_a"], row["node_b"], weight=row["cost"])
    return graph


def change_idx_to_outposts_ids(df_routes, outposts):
    '''
    Change routes encoding from outpost index to outpost id.
    Solvers don't use global outpost id field.
    '''
    for idx, row in df_routes.iterrows():
        route = row.route
        route = [outposts.iloc[i].outpost_id for i in route]
        row.route = route
        df_routes.iloc[idx] = row
    return df_routes


def solve(datadir, solver_name='ortools', calculation_time=5, savedir='.',
        vehicles_list=None, limit_outposts=None, max_route_distance=200000):
    '''
    Import data from `datadir` and find solution using `solver`.

    Args:
        datadir: data files directory
        solver_name: solver type to use
        calculation_time: suggested calculation time in seconds
        savedir: directory to save result
        vehicles_list: list of `k:load`, if None load from file
        limit_outposts: if not `None`, take given number of outposts from
            the beginning of the list and try to find the solution

    Returns:
        Dataframe containing generated routes.
    '''
    outposts_path = os.path.join(datadir, "outposts.csv")
    graph_path = os.path.join(datadir, "graph.csv")
    vehicles_path = os.path.join(datadir, "vehicles.csv")

    log.info('Importing data...')
    outposts = pd.read_csv(outposts_path, sep=';')
    graph_df = pd.read_csv(graph_path, sep=';')

    if limit_outposts is not None:
        log.warn('\033[93mWARRNING! WE ARE SOLVING VRP PROBLEM ONLY FOR FIRST %d OUTPOSTS\033[0m' % limit_outposts)
        outposts = outposts.loc[[0] + list(range(1, limit_outposts))]

    load_vehicles = vehicles_list is None
    if load_vehicles:
        vehicles = pd.read_csv(vehicles_path, sep=';')
    else:
        log.info('Generating vehicles fleet...')
        gen_data = [(float(c), int(k)) for k, c in [tuple(x.split(':')) for x in vehicles_list]]
        vehicles = generate_vehicles(gen_data)

    starting_point = 0

    total_load = outposts['load'].sum()
    total_capacity = sum(vehicles['capacity'].values)
    log.info('Total outposts load left: %.2f' % total_load)
    log.info('Total vehicles capacity: %.2f' % total_capacity)

    if  total_load > total_capacity:
        log.error('We are not able to handle all packages! Total load %.2f \
is greater than total capacity %.2f' % (total_load, total_capacity))
        exit(0)

    log.info('Preprocess outposts...')
    outposts, vehicles_left, vehicles_used = outposts_preprocessing(outposts, vehicles)
    if outposts is None:
        log.error('All vehicles used in preprocessing phase! Use greater fleet!')
        exit(0)

    log.info('Special vehicles should be delegated to:')
    for outpost_id, vehicle_id, vehicle_capacity in vehicles_used:
        log.info('Outpost Id: {:4d} Vehicle Id: {:4d} Vehicle capacity: \
{:4.1f}'.format(outpost_id, vehicle_id, vehicle_capacity))

    log.info('Preprocessed outposts list:')
    log.info(outposts[['outpost_id', 'outpost_name', 'load']])

    # Argparse doesn't allow to enter not existing dict key, no need to check it again
    solver = dict(SOLVERS)[solver_name]

    log.info('Building graph...')
    # Build graph at the end, when outposts loads are updated
    graph = read_graph_from_df(graph_df, outposts)

    log.info('Running solver...')
    log.info('Max distance per route is: %.0f m' % max_route_distance)
    time_start = time.time()
    df_routes = solver.calculate_routes(outposts, vehicles_left, graph, 
        starting_point=starting_point, calculation_time=calculation_time, 
        max_route_distance=max_route_distance)
    time_end = time.time()
    elapsed = (time_end - time_start) / 60.

    if df_routes is not None:
        df_routes = append_single_outposts_routes(df_routes, starting_point, vehicles_used, graph)
        df_routes = change_idx_to_outposts_ids(df_routes, outposts)
        log.info('Solution preview: \n' + str(df_routes))

        path = os.path.join(savedir, 'routes.csv')
        df_routes.to_csv(path, sep=';', index=False)
        log.info(INFO.format(datadir=datadir, solver=solver_name, elapsed=elapsed,
            savepath=path))
    return df_routes


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=RawTextHelpFormatter)
    parser.add_argument('datadir', help='Required data files directory')
    available_solvers = [k for k, _ in SOLVERS]
    default_solver = available_solvers[0]
    parser.add_argument('--solver', choices=available_solvers, 
        default=default_solver, help='Solver used to solve VRP problem. \
Default: %s' % default_solver)
    parser.add_argument('--savedir', default='.', help='Output directory for `routes.csv` file')
    parser.add_argument('--calc_time', type=int, default=5, help='Suggested calculation time. Default: 5s')
    parser.add_argument('--gen_vehicles', action='append', metavar=('k:load'), 
        help='Generate vehicles instead of loading them from `vehicle.csv`. \n\
Each use of this flag will generate `k` new vehicles of load \n\
`load` tons, where `k` is integer and `load` is float value.')
    parser.add_argument('--limit_outposts', type=int, metavar='N', 
        help='Try to solve the problem only for first `N` outposts in the \n\
`outposts.csv` file')
    parser.add_argument('-v', action='count', default=0, help='Increase level of verbosity')
    parser.add_argument('--max_distance', type=float, default=200, 
            help='Max single route distance in `km`. Default: 200 km')

    args = parser.parse_args()
    
    if args.v < 1:
        log_level = log.ERROR
    elif args.v < 2:
        log_level = log.WARNING
    elif args.v < 3:
        log_level = log.INFO
    else:
        log_level = log.DEBUG
    log.basicConfig(level=log_level, format='%(levelname)s - %(message)s')

    df_routes = solve(
                    datadir=args.datadir, 
                    solver_name=args.solver, 
                    savedir=args.savedir,
                    max_route_distance=args.max_distance * 1000,
                    calculation_time=args.calc_time, 
                    vehicles_list=args.gen_vehicles,
                    limit_outposts=args.limit_outposts)

